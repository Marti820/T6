{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 6: Redes Nueronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 1. Clasificación con redes neuronales - Datos iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos, Selección y División"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga Datos Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selección de Especimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(iris.target, num_classes=3)\n",
    "y_s = y[:,[0]]\n",
    "y_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "División de datos (entrenamiento, validación, prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    iris.data, y_s, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scl = StandardScaler()\n",
    "std_scl.fit(X_train)\n",
    "\n",
    "print(X_train[0:3,])\n",
    "X_train = std_scl.transform(X_train)\n",
    "print(X_train[0:3,])\n",
    "X_valid = std_scl.transform(X_valid)\n",
    "X_test = std_scl.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación del modelo base (capa de entrada, capa oculta con 8 neuronas y una capa de salida comn una neurona para la única categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "base = tf.keras.Sequential()\n",
    "base.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "base.add(tf.keras.layers.Dense(8, activation=\"relu\"))\n",
    "base.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_base = base.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafica historial de pérdida de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_base.history['loss'], label='loss')\n",
    "plt.plot(history_base.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "y_pred_base = base.predict(X_test)\n",
    "#y_pred_base_classes = np.argmax(y_pred_base, axis=1)\n",
    "#y_pred_base_classes\n",
    "y_pred_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0][0])\n",
    "print(y_pred_base[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.astype(int).flatten().tolist()\n",
    "\n",
    "def to_binary_predictions(array, threshold=0.5):\n",
    "    return (array >= threshold).astype(int)\n",
    "\n",
    "# Example usage:\n",
    "y_pred_base = to_binary_predictions(y_pred_base)\n",
    "\n",
    "print(y_pred_base)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred_base)\n",
    "precision = precision_score(y_test, y_pred_base)\n",
    "recall = recall_score(y_test, y_pred_base)\n",
    "f1 = f1_score(y_test, y_pred_base)\n",
    "f2 = fbeta_score(y_test, y_pred_base, beta=2)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_base)\n",
    "\n",
    "print(\"--- MÉTRICAS DEL MODELO (Entrenamiento) ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"F2 Score: {f2:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_base)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels = ['No Setosa', 'Setosa'], yticklabels= ['No Setosa', 'Setosa'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusión - Test')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Evaluación en conjunto de validación\n",
    "y_pred_base_validation = base.predict(X_valid)\n",
    "y_pred_base_validation = to_binary_predictions(y_pred_base_validation)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_valid, y_pred_base_validation)\n",
    "precision = precision_score(y_valid, y_pred_base_validation)\n",
    "recall = recall_score(y_valid, y_pred_base_validation)\n",
    "f1 = f1_score(y_valid, y_pred_base_validation)\n",
    "f2 = fbeta_score(y_valid, y_pred_base_validation, beta=2)\n",
    "roc_auc = roc_auc_score(y_valid, y_pred_base_validation)\n",
    "\n",
    "print(\"--- MÉTRICAS DEL MODELO (Validación) ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"F2 Score: {f2:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_valid, y_pred_base_validation)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels =  ['No Setosa', 'Setosa'], yticklabels= ['No Setosa', 'Setosa'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusión - Validacion')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevos modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**modelo 3 capas y (10,15,20) neuronas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "m1 = tf.keras.Sequential()\n",
    "m1.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "m1.add(tf.keras.layers.Dense(10, activation=\"relu\"))\n",
    "m1.add(tf.keras.layers.Dense(15, activation=\"relu\"))\n",
    "m1.add(tf.keras.layers.Dense(20, activation=\"relu\"))\n",
    "m1.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_m1 = m1.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_m1 = m1.predict(X_test)\n",
    "y_pred_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.astype(int).flatten().tolist()\n",
    "\n",
    "def to_binary_predictions(array, threshold=0.5):\n",
    "    return (array >= threshold).astype(int)\n",
    "\n",
    "# Example usage:\n",
    "y_pred_m1 = to_binary_predictions(y_pred_m1)\n",
    "\n",
    "print(y_pred_m1)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred_m1)\n",
    "precision = precision_score(y_test, y_pred_m1)\n",
    "recall = recall_score(y_test, y_pred_m1)\n",
    "f1 = f1_score(y_test, y_pred_m1)\n",
    "f2 = fbeta_score(y_test, y_pred_m1, beta=2)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_m1)\n",
    "\n",
    "print(\"--- MÉTRICAS DEL MODELO (Entrenamiento) ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"F2 Score: {f2:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_m1)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels = ['No Setosa', 'Setosa'], yticklabels= ['No Setosa', 'Setosa'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusión - Test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**modelo 5 capas y (5,7,21,30,5) neuronas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "m2 = tf.keras.Sequential()\n",
    "m2.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "m2.add(tf.keras.layers.Dense(5, activation=\"relu\"))\n",
    "m2.add(tf.keras.layers.Dense(7, activation=\"relu\"))\n",
    "m2.add(tf.keras.layers.Dense(21, activation=\"relu\"))\n",
    "m2.add(tf.keras.layers.Dense(30, activation=\"relu\"))\n",
    "m2.add(tf.keras.layers.Dense(5, activation=\"relu\"))\n",
    "m2.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_m2 = m2.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_m2 = m2.predict(X_test)\n",
    "y_pred_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.astype(int).flatten().tolist()\n",
    "\n",
    "def to_binary_predictions(array, threshold=0.5):\n",
    "    return (array >= threshold).astype(int)\n",
    "\n",
    "# Example usage:\n",
    "y_pred_m2 = to_binary_predictions(y_pred_m2)\n",
    "\n",
    "print(y_pred_m2)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred_m2)\n",
    "precision = precision_score(y_test, y_pred_m2)\n",
    "recall = recall_score(y_test, y_pred_m2)\n",
    "f1 = f1_score(y_test, y_pred_m2)\n",
    "f2 = fbeta_score(y_test, y_pred_m2, beta=2)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_m2)\n",
    "\n",
    "print(\"--- MÉTRICAS DEL MODELO (Entrenamiento) ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"F2 Score: {f2:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_m2)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels = ['No Setosa', 'Setosa'], yticklabels= ['No Setosa', 'Setosa'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusión - Test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**modelo 4 capas y (8,20,35,46) neuronas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "m3 = tf.keras.Sequential()\n",
    "m3.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "m3.add(tf.keras.layers.Dense(8, activation=\"relu\"))\n",
    "m3.add(tf.keras.layers.Dense(20, activation=\"relu\"))\n",
    "m3.add(tf.keras.layers.Dense(35, activation=\"relu\"))\n",
    "m3.add(tf.keras.layers.Dense(46, activation=\"relu\"))\n",
    "m3.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_m3 = m3.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_m3 = m3.predict(X_test)\n",
    "y_pred_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.astype(int).flatten().tolist()\n",
    "\n",
    "def to_binary_predictions(array, threshold=0.5):\n",
    "    return (array >= threshold).astype(int)\n",
    "\n",
    "# Example usage:\n",
    "y_pred_m3 = to_binary_predictions(y_pred_m3)\n",
    "\n",
    "print(y_pred_m3)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred_m3)\n",
    "precision = precision_score(y_test, y_pred_m3)\n",
    "recall = recall_score(y_test, y_pred_m3)\n",
    "f1 = f1_score(y_test, y_pred_m3)\n",
    "f2 = fbeta_score(y_test, y_pred_m3, beta=2)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_m3)\n",
    "\n",
    "print(\"--- MÉTRICAS DEL MODELO (Entrenamiento) ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"F2 Score: {f2:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_m3)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels = ['No Setosa', 'Setosa'], yticklabels= ['No Setosa', 'Setosa'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusión - Test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 2: Clasificacion con redes neuronales - Datos heart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seleccion de variables:**\n",
    "Se seleccionan el siguinete subconjunto de variables: \n",
    "\n",
    "categoricas numericas: 'sex', 'exang', 'fbs'\n",
    "\n",
    "categorica string: 'thal'\n",
    "\n",
    "numerica: 'age', 'trestbps', 'chol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['cp', 'restecg','ca','thalach', 'oldpeak', 'slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_int_feats = ['sex', 'fbs', 'exang']\n",
    "cat_str_feats = ['thal']\n",
    "num_feats = ['age', 'trestbps', 'chol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_ordered = cat_int_feats+cat_str_feats+num_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[feats_ordered+['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separacion de conjuntos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.8, random_state=100)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.drop(train.index)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = train.sample(frac=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para convertir de dataframe (pandas) a dataset (tensorflow), separando características y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataframe_to_dataset(train)\n",
    "val_ds = dataframe_to_dataset(val)\n",
    "test_ds = dataframe_to_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "val_ds = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Crea capa de normalización para este feature\n",
    "    normalizer = keras.layers.Normalization()\n",
    "\n",
    "    # Prepara el dataset para considerar únicamente la feature de interés (name)\n",
    "    feature_ds = dataset.map(lambda x, y: x[name]) # selecciona variable\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1)) # deja el tensor de una dimensión\n",
    "\n",
    "    # Aprende las estadísticas de los datos (media, varianza)\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Aplica la normalización a la variable\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = keras.layers.StringLookup if is_string else keras.layers.IntegerLookup\n",
    "    # Crea una capa Lookup para retornas variables 0/1 (dummies)\n",
    "    # lookup: busca el valor correspondiente de la variable categórica\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepara el dataset para considerar únicamente la feature de interés (name)\n",
    "    feature_ds = dataset.map(lambda x, y: x[name]) # selecciona variable\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1)) # deja el tensor de una dimensión\n",
    "\n",
    "    # Aprende el conjunto de posibles valores que toma la variable categórica y asigna enteros\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Aplica la conversión de categorías a enteros\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in cat_int_feats:\n",
    "  inputs.append(keras.Input(shape=(1,), name=i, dtype=\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_str_feats:\n",
    "  inputs.append(keras.Input(shape=(1,), name=i, dtype=\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_feats:\n",
    "  inputs.append(keras.Input(shape=(1,), name=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in inputs:\n",
    "   print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_encoded=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,feat in enumerate(cat_int_feats):\n",
    "  feats_encoded.append(\n",
    "      encode_categorical_feature(inputs[i], feat, train_ds, False)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_feats = len(feats_encoded)\n",
    "len_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,feat in enumerate(cat_str_feats):\n",
    "  feats_encoded.append(\n",
    "      encode_categorical_feature(inputs[len_feats+i], feat, train_ds, True)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_feats = len(feats_encoded)\n",
    "len_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,feat in enumerate(num_feats):\n",
    "  feats_encoded.append(\n",
    "      encode_numerical_feature(inputs[len_feats+i], feat, train_ds)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in feats_encoded:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una capa concatenando todas las variables codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = keras.layers.concatenate(feats_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos una capa densa con 32 neuronas y función de activación relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers = keras.layers.Dense(32, activation='relu')(all_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una capa concatenando todas las variables codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers = keras.layers.Dense(1, activation='sigmoid')(model_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el modelo con las capas ya creadas y las variables de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs, model_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el modelo, definiendo optimizador, función de pérdida y métricas adicionales a capturar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aseguramos que Keras use TensorFlow como backend, para asegurar que el modelo pueda usar strings como entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamineto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostory = model.fit(train_ds, epochs=100, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_ds)\n",
    "y_pred_modelo= model.predict(test_ds)\n",
    "print(len(y_pred_modelo))\n",
    "y_pred_modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hostory.history['loss'], label='loss')\n",
    "plt.plot(hostory.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate([y.numpy() for _, y in test_ds], axis=0)\n",
    "print(y_true)\n",
    "print(len(y_true))\n",
    "\n",
    "def to_binary_predictions(array, threshold=0.5):\n",
    "    return (array >= threshold).astype(int)\n",
    "\n",
    "# Example usage:\n",
    "y_pred_modelo = to_binary_predictions(y_pred_modelo)\n",
    "\n",
    "print(y_pred_modelo)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluación\n",
    "accuracy = accuracy_score(y_true, y_pred_modelo)\n",
    "precision = precision_score(y_true, y_pred_modelo)\n",
    "recall = recall_score(y_true, y_pred_modelo)\n",
    "f1 = f1_score(y_true, y_pred_modelo)\n",
    "f2 = fbeta_score(y_true, y_pred_modelo, beta=2)\n",
    "roc_auc = roc_auc_score(y_true, y_pred_modelo)\n",
    "\n",
    "print(\"--- MÉTRICAS DEL MODELO (Entrenamiento) ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"F2 Score: {f2:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_modelo)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')#, xticklabels = ['No Setosa', 'Setosa'], yticklabels= ['No Setosa', 'Setosa'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusión - Test')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
